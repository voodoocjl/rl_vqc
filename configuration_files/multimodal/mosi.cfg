[general]
episodes = 40000

[env]
num_qubits = 4
num_layers = 40
fake_min_energy = 1.1
fn_type = incremental_with_fixed_ends
accept_err = 0.5
shift_threshold_time = 500
shift_threshold_ball = 0.05
success_thresh = 25
succ_radius_shift = 10
succes_switch = 4
thresholds = []
switch_episodes = []
curriculum_type = MovingThreshold

[problem]
ham_type = MOSI
geometry = Li .0 .0 .0; H .0 .0 3.4
taper = 1
mapping = parity

[agent]
batch_size = 400
memory_size = 2000
neurons = [1000,1000,1000,1000,1000]
dropout = 0.
learning_rate = 0.0001
angles = 0
en_state = 1
agent_type = DeepQ
agent_class = DQN
init_net = 0

update_target_net = 500
final_gamma = 0.005
epsilon_decay = 0.9999
epsilon_min = 0.05
epsilon_restart = 1.0

[architecture]
num_qubits = 4
num_layers = 40
a_insize = 74
v_insize = 35
t_insize = 300
a_hidsize = 3  
v_hidsize = 3  
t_hidsize = 6 
clr = 0.005
qlr = 0.05
epochs = 3
batch_size = 32

[non_local_opt]
global_iters = 100
method = scipy_each_step
optim_alg = COBYLA
local_size = None